<!DOCTYPE html>
<html lang="en-US">
<head>
    <meta charset="utf-8" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Work+Sans:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">
    <meta name="viewport" content="width=device-width" />
    <meta name="author" content="Michele Gatti" />
    <meta name="description" content="Welcome to my portfolio website" />
    <title>SpecchioSonoro</title>
    <link rel="stylesheet" href="specchiosonoro-styles.css"> 
</head>
</head>
<body>
    <header class="header">
        <a href="../../index/index.html" class="logo">MG</a>
        <nav class="nav">
            <a href="../../experiments/eperiments.html">Experiments</a>
            <a href="../../about/about.html">About</a>
        </nav>
    </header>

    <div class="project-container">
        <div class="project">
            <div class="project-content">
                <!-- YouTube Embed -->
                <div class="project-video">
                    <div class="youtube-embed-container">
                        <iframe src="https://www.youtube.com/embed/iodsaakZLrY" 
                                frameborder="0" 
                                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                allowfullscreen></iframe>
                    </div>
                </div>

                <!-- Text and Download Button -->
                <div class="project-text">
                    <h1>Specchio Sonoro</h1>
                    <h2><strong>Tags:</strong> Computer Vision - Speculative - Real-Time</h2>
                    <h2><strong>Tools:</strong> TouchDesigner - Max 8</h2>
                    <h3>This interactive audiovisual project bridges computer vision and real-time processing to create an immersive experience that heightens awareness of subtle facial movements. Using MediaPipe in TouchDesigner, I tracked facial landmarks with precision, mapping micro-gestures—like eyebrow raises, lip twitches, and jaw tension—to dynamic generative parameters.

                        Each movement triggers responsive transformations, translating unconscious expressions into real-time feedback. The goal is to foster a deeper connection between body and perception, inviting users to explore the often-overlooked nuances of their own expressions. By visualizing and modulating these micro-movements, the project reveals the hidden poetry of human expression, blending generative patterns with biometric interactivity.</h3>
                    <h3><strong>Sound:</strong> Juergen Branz - Sound pack for motion designers</h3>

                    <!-- Aligned Download PDF Button -->
                    <div class="download-pdf">
                        <a href="./specchiosonoro_materials/presentazione esame_gatti michele.pdf" download>
                            <button class="download-btn"> Presentation (ITA)</button>
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </div>
</body>
</html>

